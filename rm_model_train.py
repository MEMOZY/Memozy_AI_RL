import pandas as pd
import re
import json
import random
from collections import defaultdict
import matplotlib.pyplot as plt


from sentence_transformers import SentenceTransformer

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


from xgboost import XGBRegressor


import joblib


# --- JSONL ë¡œë”© ---
def load_jsonl(path):
    data = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            record = json.loads(line)
            caption = record.get("caption", "")
            rate = float(record.get("rate", 0.0))
            data.append({"text": caption, "rate": rate})
    return pd.DataFrame(data)


# --- í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ---
def preprocess_text(text):
    text = re.sub(r'[^ê°€-í£\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text


# --- Oversampling í•¨ìˆ˜ ---
def apply_oversampling(df, num_bins=5):
    rate_buckets = defaultdict(list)

    # ê· ë“±í•˜ê²Œ ë¶„í• í•  ìˆ˜ ìˆë„ë¡ rateë¥¼ ë²„í‚·ìœ¼ë¡œ ë‚˜ëˆ”
    min_rate, max_rate = df['rate'].min(), df['rate'].max()
    bin_size = (max_rate - min_rate) / num_bins

    def bucket_idx(rate):
        return int((rate - min_rate) // bin_size)

    for _, row in df.iterrows():
        idx = bucket_idx(row['rate'])
        rate_buckets[idx].append(row)

    # Oversampling
    max_count = max(len(samples) for samples in rate_buckets.values())
    balanced_samples = []

    for samples in rate_buckets.values():
        if len(samples) < max_count:
            oversampled = random.choices(samples, k=max_count - len(samples))
            balanced_samples.extend(samples + oversampled)
        else:
            balanced_samples.extend(samples)

    random.shuffle(balanced_samples)
    return pd.DataFrame(balanced_samples)


# --- ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ---
df = load_jsonl("./data/RM_data/caption/human_rated_gpt_output.jsonl")
df['cleaned_text'] = df['text'].apply(preprocess_text)

# --- Oversampling ---
df_balanced = apply_oversampling(df)

# --- BERT ì„ë² ë”© ---
bert_model = SentenceTransformer('distiluse-base-multilingual-cased-v2')  # í•œêµ­ì–´ í¬í•¨ ë©€í‹°ë§êµ¬ì–¼

X = bert_model.encode(df_balanced['cleaned_text'].tolist(), show_progress_bar=True)
y = df_balanced['rate'].values

# --- Train/Test ë¶„í•  ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- ëª¨ë¸ í•™ìŠµ ---
# model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42) # MSE: 0.07910551549026897 MAE: 0.17151935618020955  RÂ² Score: 0.8379005347899992
model = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42) # MSE: 0.05698540368337747 MAE: 0.1266120111062275 RÂ² Score: 0.889218881686483
# model = LGBMRegressor(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42) #MSE: 0.0939286415107616 MAE: 0.17242499403145833 RÂ² Score: 0.8190963099966417
# model = CatBoostRegressor(iterations=300, learning_rate=0.05, depth=5, verbose=0, random_state=42) #MSE: 0.09919866752873258 MAE: 0.21750172460502057 RÂ² Score: 0.8048769870784058
# model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42) #MSE: 0.07921171972602306 MAE: 0.2027260982172313  RÂ² Score: 0.838990149670999
model.fit(X_train, y_train)

# --- ì˜ˆì¸¡ ë° í‰ê°€ ---
preds = model.predict(X_test)
print("ğŸ“‰ MSE:", mean_squared_error(y_test, preds))
print("ğŸ“ˆ MAE:", mean_absolute_error(y_test, preds))
print("ğŸ” RÂ² Score:", r2_score(y_test, preds))

#---  ëª¨ë¸ ì €ì¥ ---
joblib.dump(model, 'XGBRegressor_model.pkl')

"""
ğŸ“‰ MSE: 0.06523728399644124
ğŸ“ˆ MAE: 0.13134160440158613
ğŸ” RÂ² Score: 0.8713930435161695
"""
### --- ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ---
# ì¸ë±ìŠ¤ ìˆœì„œ
x = list(range(len(y_test)))

plt.figure(figsize=(14, 6))

# ì‹¤ì œ rate (ë¹¨ê°„ ì„ )
plt.plot(x, y_test, label='Label Rate', color='red', linewidth=2)

# ì˜ˆì¸¡ rate (íŒŒë€ ì„ )
plt.plot(x, preds, label='Predict Rate', color='blue', linewidth=2)

plt.xlabel("Test Sample Index")
plt.ylabel("Rate")
plt.title("ğŸ“ˆ Label Rate vs Predict Rate")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
